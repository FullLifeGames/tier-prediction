{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa256081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import T\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c07f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(677, 13)\n",
      "Using 542 samples for training and 135 for validation\n",
      "Input: {'hp': <tf.Tensor: shape=(), dtype=int64, numpy=80>, 'atk': <tf.Tensor: shape=(), dtype=int64, numpy=135>, 'def': <tf.Tensor: shape=(), dtype=int64, numpy=130>, 'spa': <tf.Tensor: shape=(), dtype=int64, numpy=95>, 'spd': <tf.Tensor: shape=(), dtype=int64, numpy=90>, 'speed': <tf.Tensor: shape=(), dtype=int64, numpy=70>, 'ability1': <tf.Tensor: shape=(), dtype=string, numpy=b'Clear Body'>, 'ability2': <tf.Tensor: shape=(), dtype=string, numpy=b''>, 'ability3': <tf.Tensor: shape=(), dtype=string, numpy=b'Light Metal'>, 'type1': <tf.Tensor: shape=(), dtype=string, numpy=b'Steel'>, 'type2': <tf.Tensor: shape=(), dtype=string, numpy=b'Psychic'>}\n",
      "Target: tf.Tensor([0 0 0 0 1 0 0 0], shape=(8,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# From: https://keras.io/examples/structured_data/structured_data_classification_from_scratch/\n",
    "\n",
    "dataframe = pd.read_csv(\"./test.csv\", keep_default_na=False)\n",
    "\n",
    "print(dataframe.shape)\n",
    "\n",
    "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")\n",
    "\n",
    "mlb = LabelBinarizer()\n",
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    dataframe.pop(\"name\")\n",
    "    labels = dataframe.pop(\"tier\")\n",
    "    labels = mlb.fit_transform(labels)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)\n",
    "\n",
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98db04ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)\n",
    "\n",
    "from tensorflow.keras.layers import IntegerLookup\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_categorical_feature(feature, name, dataset, is_string):\n",
    "    lookup_class = StringLookup if is_string else IntegerLookup\n",
    "    # Create a lookup layer which will turn strings into integer indices\n",
    "    lookup = lookup_class(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "# Categorical features encoded as integers\n",
    "hp = keras.Input(shape=(1,), name=\"hp\", dtype=\"int64\")\n",
    "atk = keras.Input(shape=(1,), name=\"atk\", dtype=\"int64\")\n",
    "defe = keras.Input(shape=(1,), name=\"def\", dtype=\"int64\")\n",
    "spa = keras.Input(shape=(1,), name=\"spa\", dtype=\"int64\")\n",
    "spd = keras.Input(shape=(1,), name=\"spd\", dtype=\"int64\")\n",
    "speed = keras.Input(shape=(1,), name=\"speed\", dtype=\"int64\")\n",
    "#strongestAttack = keras.Input(shape=(1,), name=\"strongestAttack\", dtype=\"int64\")\n",
    "#recovery = keras.Input(shape=(1,), name=\"recovery\", dtype=\"int64\")\n",
    "#coverageAttacks = keras.Input(shape=(1,), name=\"coverageAttacks\", dtype=\"int64\")\n",
    "prevo = keras.Input(shape=(1,), name=\"prevo\", dtype=\"int64\")\n",
    "\n",
    "# Categorical feature encoded as string\n",
    "ability1 = keras.Input(shape=(1,), name=\"ability1\", dtype=\"string\")\n",
    "ability2 = keras.Input(shape=(1,), name=\"ability2\", dtype=\"string\")\n",
    "ability3 = keras.Input(shape=(1,), name=\"ability3\", dtype=\"string\")\n",
    "type1 = keras.Input(shape=(1,), name=\"type1\", dtype=\"string\")\n",
    "type2 = keras.Input(shape=(1,), name=\"type2\", dtype=\"string\")\n",
    "\n",
    "\n",
    "all_inputs = [\n",
    "    hp,\n",
    "    atk,\n",
    "    defe,\n",
    "    spa,\n",
    "    spd,\n",
    "    speed,\n",
    "    #strongestAttack,\n",
    "    #recovery,\n",
    "    #coverageAttacks,\n",
    "    ##prevo,\n",
    "    ability1,\n",
    "    ability2,\n",
    "    ability3,\n",
    "    type1,\n",
    "    type2,\n",
    "]\n",
    "\n",
    "# Integer categorical features\n",
    "#recovery_encoded = encode_categorical_feature(recovery, \"recovery\", train_ds, False)\n",
    "#prevo_encoded = encode_categorical_feature(prevo, \"prevo\", train_ds, False)\n",
    "\n",
    "# String categorical features\n",
    "ability1_encoded = encode_categorical_feature(ability1, \"ability1\", train_ds, True)\n",
    "ability2_encoded = encode_categorical_feature(ability2, \"ability2\", train_ds, True)\n",
    "ability3_encoded = encode_categorical_feature(ability3, \"ability3\", train_ds, True)\n",
    "type1_encoded = encode_categorical_feature(type1, \"type1\", train_ds, True)\n",
    "type2_encoded = encode_categorical_feature(type2, \"type2\", train_ds, True)\n",
    "\n",
    "# Numerical features\n",
    "hp_encoded = encode_numerical_feature(hp, \"hp\", train_ds)\n",
    "atk_encoded = encode_numerical_feature(atk, \"atk\", train_ds)\n",
    "defe_encoded = encode_numerical_feature(defe, \"def\", train_ds)\n",
    "spa_encoded = encode_numerical_feature(spa, \"spa\", train_ds)\n",
    "spd_encoded = encode_numerical_feature(spd, \"spd\", train_ds)\n",
    "speed_encoded = encode_numerical_feature(speed, \"speed\", train_ds)\n",
    "#strongestAttack_encoded = encode_numerical_feature(strongestAttack, \"strongestAttack\", train_ds)\n",
    "#coverageAttacks_encoded = encode_numerical_feature(coverageAttacks, \"coverageAttacks\", train_ds)\n",
    "\n",
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        hp_encoded,\n",
    "        atk_encoded,\n",
    "        defe_encoded,\n",
    "        spa_encoded,\n",
    "        spd_encoded,\n",
    "        speed_encoded,\n",
    "        #strongestAttack_encoded,\n",
    "        #recovery_encoded,\n",
    "        #coverageAttacks_encoded,\n",
    "        #prevo_encoded,\n",
    "        ability1_encoded,\n",
    "        ability2_encoded,\n",
    "        ability3_encoded,\n",
    "        type1_encoded,\n",
    "        type2_encoded,\n",
    "    ]\n",
    ")\n",
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(len(mlb.classes_), activation=\"sigmoid\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "004baab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "17/17 [==============================] - 1s 19ms/step - loss: 0.6814 - accuracy: 0.1402 - val_loss: 0.6640 - val_accuracy: 0.2741\n",
      "Epoch 2/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.6333 - accuracy: 0.1587 - val_loss: 0.5763 - val_accuracy: 0.2963\n",
      "Epoch 3/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.5202 - accuracy: 0.1642 - val_loss: 0.4113 - val_accuracy: 0.2741\n",
      "Epoch 4/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4354 - accuracy: 0.2232 - val_loss: 0.3509 - val_accuracy: 0.2593\n",
      "Epoch 5/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3891 - accuracy: 0.2823 - val_loss: 0.3301 - val_accuracy: 0.2889\n",
      "Epoch 6/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3356 - accuracy: 0.3672 - val_loss: 0.3107 - val_accuracy: 0.3259\n",
      "Epoch 7/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3169 - accuracy: 0.4133 - val_loss: 0.2941 - val_accuracy: 0.4593\n",
      "Epoch 8/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.4502 - val_loss: 0.2888 - val_accuracy: 0.4889\n",
      "Epoch 9/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2852 - accuracy: 0.5037 - val_loss: 0.2742 - val_accuracy: 0.5185\n",
      "Epoch 10/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2692 - accuracy: 0.5406 - val_loss: 0.2654 - val_accuracy: 0.5111\n",
      "Epoch 11/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2553 - accuracy: 0.5793 - val_loss: 0.2622 - val_accuracy: 0.5333\n",
      "Epoch 12/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2432 - accuracy: 0.5867 - val_loss: 0.2575 - val_accuracy: 0.5407\n",
      "Epoch 13/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2319 - accuracy: 0.6070 - val_loss: 0.2570 - val_accuracy: 0.5259\n",
      "Epoch 14/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2248 - accuracy: 0.6236 - val_loss: 0.2502 - val_accuracy: 0.5259\n",
      "Epoch 15/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2167 - accuracy: 0.6421 - val_loss: 0.2536 - val_accuracy: 0.5556\n",
      "Epoch 16/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2146 - accuracy: 0.6402 - val_loss: 0.2529 - val_accuracy: 0.5407\n",
      "Epoch 17/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2021 - accuracy: 0.6421 - val_loss: 0.2541 - val_accuracy: 0.5852\n",
      "Epoch 18/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1852 - accuracy: 0.6753 - val_loss: 0.2522 - val_accuracy: 0.5407\n",
      "Epoch 19/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1799 - accuracy: 0.6808 - val_loss: 0.2638 - val_accuracy: 0.5481\n",
      "Epoch 20/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1839 - accuracy: 0.6882 - val_loss: 0.2634 - val_accuracy: 0.5852\n",
      "Epoch 21/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1620 - accuracy: 0.6956 - val_loss: 0.2692 - val_accuracy: 0.5852\n",
      "Epoch 22/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1649 - accuracy: 0.7030 - val_loss: 0.2756 - val_accuracy: 0.5852\n",
      "Epoch 23/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1574 - accuracy: 0.7232 - val_loss: 0.2708 - val_accuracy: 0.5778\n",
      "Epoch 24/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1542 - accuracy: 0.7159 - val_loss: 0.2797 - val_accuracy: 0.5926\n",
      "Epoch 25/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1520 - accuracy: 0.7343 - val_loss: 0.2865 - val_accuracy: 0.5778\n",
      "Epoch 26/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1366 - accuracy: 0.7362 - val_loss: 0.2969 - val_accuracy: 0.6074\n",
      "Epoch 27/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1372 - accuracy: 0.7491 - val_loss: 0.3093 - val_accuracy: 0.6296\n",
      "Epoch 28/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1312 - accuracy: 0.7583 - val_loss: 0.3104 - val_accuracy: 0.5704\n",
      "Epoch 29/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1329 - accuracy: 0.7509 - val_loss: 0.3120 - val_accuracy: 0.5852\n",
      "Epoch 30/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1266 - accuracy: 0.7491 - val_loss: 0.3178 - val_accuracy: 0.5852\n",
      "Epoch 31/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1271 - accuracy: 0.7657 - val_loss: 0.3276 - val_accuracy: 0.5778\n",
      "Epoch 32/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1235 - accuracy: 0.7897 - val_loss: 0.3329 - val_accuracy: 0.6000\n",
      "Epoch 33/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1209 - accuracy: 0.7878 - val_loss: 0.3339 - val_accuracy: 0.5778\n",
      "Epoch 34/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1148 - accuracy: 0.7934 - val_loss: 0.3432 - val_accuracy: 0.6000\n",
      "Epoch 35/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1054 - accuracy: 0.8137 - val_loss: 0.3518 - val_accuracy: 0.5852\n",
      "Epoch 36/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1076 - accuracy: 0.8007 - val_loss: 0.3628 - val_accuracy: 0.6000\n",
      "Epoch 37/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1001 - accuracy: 0.8284 - val_loss: 0.3746 - val_accuracy: 0.5926\n",
      "Epoch 38/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1001 - accuracy: 0.8321 - val_loss: 0.3790 - val_accuracy: 0.6000\n",
      "Epoch 39/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1027 - accuracy: 0.8173 - val_loss: 0.3839 - val_accuracy: 0.5926\n",
      "Epoch 40/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1008 - accuracy: 0.8155 - val_loss: 0.3970 - val_accuracy: 0.5704\n",
      "Epoch 41/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0949 - accuracy: 0.8358 - val_loss: 0.4002 - val_accuracy: 0.5852\n",
      "Epoch 42/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0866 - accuracy: 0.8579 - val_loss: 0.4043 - val_accuracy: 0.5778\n",
      "Epoch 43/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0876 - accuracy: 0.8450 - val_loss: 0.4253 - val_accuracy: 0.5778\n",
      "Epoch 44/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0894 - accuracy: 0.8561 - val_loss: 0.4317 - val_accuracy: 0.5704\n",
      "Epoch 45/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0832 - accuracy: 0.8782 - val_loss: 0.4404 - val_accuracy: 0.5407\n",
      "Epoch 46/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0787 - accuracy: 0.8764 - val_loss: 0.4619 - val_accuracy: 0.5704\n",
      "Epoch 47/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0818 - accuracy: 0.8690 - val_loss: 0.4660 - val_accuracy: 0.5778\n",
      "Epoch 48/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0765 - accuracy: 0.8856 - val_loss: 0.4877 - val_accuracy: 0.5704\n",
      "Epoch 49/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0742 - accuracy: 0.8856 - val_loss: 0.4940 - val_accuracy: 0.5852\n",
      "Epoch 50/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0767 - accuracy: 0.8819 - val_loss: 0.4980 - val_accuracy: 0.5852\n",
      "Epoch 51/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0715 - accuracy: 0.9022 - val_loss: 0.4916 - val_accuracy: 0.5926\n",
      "Epoch 52/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0647 - accuracy: 0.9188 - val_loss: 0.5299 - val_accuracy: 0.5481\n",
      "Epoch 53/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0748 - accuracy: 0.9004 - val_loss: 0.5287 - val_accuracy: 0.5630\n",
      "Epoch 54/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0719 - accuracy: 0.8838 - val_loss: 0.5336 - val_accuracy: 0.5852\n",
      "Epoch 55/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0698 - accuracy: 0.9004 - val_loss: 0.5589 - val_accuracy: 0.5704\n",
      "Epoch 56/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0751 - accuracy: 0.8967 - val_loss: 0.5644 - val_accuracy: 0.5481\n",
      "Epoch 57/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0682 - accuracy: 0.9133 - val_loss: 0.5573 - val_accuracy: 0.5704\n",
      "Epoch 58/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0694 - accuracy: 0.9077 - val_loss: 0.5727 - val_accuracy: 0.5630\n",
      "Epoch 59/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0589 - accuracy: 0.9317 - val_loss: 0.5907 - val_accuracy: 0.5481\n",
      "Epoch 60/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0558 - accuracy: 0.9446 - val_loss: 0.6159 - val_accuracy: 0.5333\n",
      "Epoch 61/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0649 - accuracy: 0.9188 - val_loss: 0.6138 - val_accuracy: 0.5556\n",
      "Epoch 62/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0606 - accuracy: 0.9170 - val_loss: 0.6226 - val_accuracy: 0.5778\n",
      "Epoch 63/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0607 - accuracy: 0.9299 - val_loss: 0.6402 - val_accuracy: 0.5407\n",
      "Epoch 64/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0613 - accuracy: 0.9207 - val_loss: 0.6503 - val_accuracy: 0.5704\n",
      "Epoch 65/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0537 - accuracy: 0.9391 - val_loss: 0.6413 - val_accuracy: 0.5630\n",
      "Epoch 66/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0577 - accuracy: 0.9207 - val_loss: 0.6516 - val_accuracy: 0.5630\n",
      "Epoch 67/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0570 - accuracy: 0.9207 - val_loss: 0.6578 - val_accuracy: 0.5481\n",
      "Epoch 68/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0560 - accuracy: 0.9244 - val_loss: 0.6566 - val_accuracy: 0.5704\n",
      "Epoch 69/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0523 - accuracy: 0.9410 - val_loss: 0.7013 - val_accuracy: 0.5852\n",
      "Epoch 70/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0533 - accuracy: 0.9391 - val_loss: 0.7003 - val_accuracy: 0.5333\n",
      "Epoch 71/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0565 - accuracy: 0.9151 - val_loss: 0.7158 - val_accuracy: 0.5556\n",
      "Epoch 72/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0538 - accuracy: 0.9299 - val_loss: 0.7424 - val_accuracy: 0.5778\n",
      "Epoch 73/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0554 - accuracy: 0.9299 - val_loss: 0.7331 - val_accuracy: 0.5630\n",
      "Epoch 74/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0530 - accuracy: 0.9428 - val_loss: 0.7496 - val_accuracy: 0.5852\n",
      "Epoch 75/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0508 - accuracy: 0.9483 - val_loss: 0.7585 - val_accuracy: 0.5852\n",
      "Epoch 76/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0478 - accuracy: 0.9391 - val_loss: 0.7708 - val_accuracy: 0.5778\n",
      "Epoch 77/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0433 - accuracy: 0.9557 - val_loss: 0.7785 - val_accuracy: 0.5778\n",
      "Epoch 78/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0471 - accuracy: 0.9483 - val_loss: 0.7864 - val_accuracy: 0.6000\n",
      "Epoch 79/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0406 - accuracy: 0.9594 - val_loss: 0.7905 - val_accuracy: 0.5926\n",
      "Epoch 80/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0456 - accuracy: 0.9391 - val_loss: 0.8129 - val_accuracy: 0.5778\n",
      "Epoch 81/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0511 - accuracy: 0.9336 - val_loss: 0.8095 - val_accuracy: 0.5630\n",
      "Epoch 82/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0507 - accuracy: 0.9299 - val_loss: 0.7682 - val_accuracy: 0.5630\n",
      "Epoch 83/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0529 - accuracy: 0.9170 - val_loss: 0.8160 - val_accuracy: 0.5778\n",
      "Epoch 84/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0440 - accuracy: 0.9428 - val_loss: 0.8048 - val_accuracy: 0.5556\n",
      "Epoch 85/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0464 - accuracy: 0.9557 - val_loss: 0.8553 - val_accuracy: 0.5852\n",
      "Epoch 86/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0504 - accuracy: 0.9391 - val_loss: 0.8771 - val_accuracy: 0.5778\n",
      "Epoch 87/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0487 - accuracy: 0.9465 - val_loss: 0.8602 - val_accuracy: 0.5630\n",
      "Epoch 88/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0431 - accuracy: 0.9594 - val_loss: 0.8855 - val_accuracy: 0.5778\n",
      "Epoch 89/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0482 - accuracy: 0.9410 - val_loss: 0.8751 - val_accuracy: 0.5630\n",
      "Epoch 90/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0415 - accuracy: 0.9502 - val_loss: 0.8896 - val_accuracy: 0.5630\n",
      "Epoch 91/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0390 - accuracy: 0.9520 - val_loss: 0.9489 - val_accuracy: 0.5778\n",
      "Epoch 92/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0450 - accuracy: 0.9428 - val_loss: 0.9453 - val_accuracy: 0.5778\n",
      "Epoch 93/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0436 - accuracy: 0.9576 - val_loss: 0.9624 - val_accuracy: 0.5778\n",
      "Epoch 94/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0407 - accuracy: 0.9631 - val_loss: 0.9495 - val_accuracy: 0.5556\n",
      "Epoch 95/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0382 - accuracy: 0.9539 - val_loss: 0.9705 - val_accuracy: 0.5852\n",
      "Epoch 96/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0422 - accuracy: 0.9539 - val_loss: 1.0050 - val_accuracy: 0.5704\n",
      "Epoch 97/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0406 - accuracy: 0.9557 - val_loss: 1.0085 - val_accuracy: 0.5926\n",
      "Epoch 98/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0438 - accuracy: 0.9557 - val_loss: 1.0124 - val_accuracy: 0.5704\n",
      "Epoch 99/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0389 - accuracy: 0.9557 - val_loss: 1.0533 - val_accuracy: 0.6000\n",
      "Epoch 100/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0464 - accuracy: 0.9483 - val_loss: 1.0196 - val_accuracy: 0.5704\n",
      "Epoch 101/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0369 - accuracy: 0.9668 - val_loss: 1.0334 - val_accuracy: 0.5704\n",
      "Epoch 102/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0383 - accuracy: 0.9594 - val_loss: 1.0308 - val_accuracy: 0.5778\n",
      "Epoch 103/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0419 - accuracy: 0.9539 - val_loss: 1.0712 - val_accuracy: 0.5630\n",
      "Epoch 104/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0451 - accuracy: 0.9391 - val_loss: 1.0773 - val_accuracy: 0.5407\n",
      "Epoch 105/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0450 - accuracy: 0.9410 - val_loss: 1.0889 - val_accuracy: 0.5630\n",
      "Epoch 106/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0378 - accuracy: 0.9594 - val_loss: 1.0777 - val_accuracy: 0.5630\n",
      "Epoch 107/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0362 - accuracy: 0.9539 - val_loss: 1.1025 - val_accuracy: 0.5481\n",
      "Epoch 108/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0389 - accuracy: 0.9520 - val_loss: 1.0991 - val_accuracy: 0.5704\n",
      "Epoch 109/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0418 - accuracy: 0.9428 - val_loss: 1.1490 - val_accuracy: 0.5630\n",
      "Epoch 110/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0330 - accuracy: 0.9668 - val_loss: 1.1149 - val_accuracy: 0.5704\n",
      "Epoch 111/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0397 - accuracy: 0.9613 - val_loss: 1.1611 - val_accuracy: 0.5778\n",
      "Epoch 112/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0436 - accuracy: 0.9465 - val_loss: 1.1686 - val_accuracy: 0.5778\n",
      "Epoch 113/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 0.9668 - val_loss: 1.1538 - val_accuracy: 0.5556\n",
      "Epoch 114/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 0.9631 - val_loss: 1.1901 - val_accuracy: 0.5852\n",
      "Epoch 115/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0419 - accuracy: 0.9410 - val_loss: 1.1875 - val_accuracy: 0.5556\n",
      "Epoch 116/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0410 - accuracy: 0.9520 - val_loss: 1.1837 - val_accuracy: 0.5704\n",
      "Epoch 117/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0373 - accuracy: 0.9631 - val_loss: 1.1917 - val_accuracy: 0.5926\n",
      "Epoch 118/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0364 - accuracy: 0.9539 - val_loss: 1.1999 - val_accuracy: 0.5852\n",
      "Epoch 119/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0329 - accuracy: 0.9649 - val_loss: 1.1780 - val_accuracy: 0.6000\n",
      "Epoch 120/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0397 - accuracy: 0.9557 - val_loss: 1.1899 - val_accuracy: 0.5704\n",
      "Epoch 121/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0354 - accuracy: 0.9520 - val_loss: 1.2443 - val_accuracy: 0.5926\n",
      "Epoch 122/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0299 - accuracy: 0.9686 - val_loss: 1.2372 - val_accuracy: 0.6000\n",
      "Epoch 123/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0379 - accuracy: 0.9631 - val_loss: 1.2668 - val_accuracy: 0.5704\n",
      "Epoch 124/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0387 - accuracy: 0.9483 - val_loss: 1.2464 - val_accuracy: 0.5852\n",
      "Epoch 125/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0303 - accuracy: 0.9576 - val_loss: 1.2290 - val_accuracy: 0.5852\n",
      "Epoch 126/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0397 - accuracy: 0.9465 - val_loss: 1.2554 - val_accuracy: 0.5926\n",
      "Epoch 127/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0399 - accuracy: 0.9520 - val_loss: 1.2680 - val_accuracy: 0.6000\n",
      "Epoch 128/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0294 - accuracy: 0.9649 - val_loss: 1.2785 - val_accuracy: 0.5926\n",
      "Epoch 129/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0342 - accuracy: 0.9613 - val_loss: 1.3065 - val_accuracy: 0.5852\n",
      "Epoch 130/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0317 - accuracy: 0.9594 - val_loss: 1.2938 - val_accuracy: 0.5926\n",
      "Epoch 131/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0328 - accuracy: 0.9613 - val_loss: 1.3129 - val_accuracy: 0.5778\n",
      "Epoch 132/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0329 - accuracy: 0.9594 - val_loss: 1.3043 - val_accuracy: 0.5778\n",
      "Epoch 133/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0384 - accuracy: 0.9520 - val_loss: 1.3185 - val_accuracy: 0.6074\n",
      "Epoch 134/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 0.9723 - val_loss: 1.3340 - val_accuracy: 0.6000\n",
      "Epoch 135/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0396 - accuracy: 0.9502 - val_loss: 1.3231 - val_accuracy: 0.5778\n",
      "Epoch 136/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0372 - accuracy: 0.9465 - val_loss: 1.3863 - val_accuracy: 0.5926\n",
      "Epoch 137/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0324 - accuracy: 0.9686 - val_loss: 1.3055 - val_accuracy: 0.5704\n",
      "Epoch 138/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0360 - accuracy: 0.9631 - val_loss: 1.3350 - val_accuracy: 0.6000\n",
      "Epoch 139/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0317 - accuracy: 0.9613 - val_loss: 1.3399 - val_accuracy: 0.6000\n",
      "Epoch 140/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0370 - accuracy: 0.9520 - val_loss: 1.3552 - val_accuracy: 0.6000\n",
      "Epoch 141/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0380 - accuracy: 0.9446 - val_loss: 1.3466 - val_accuracy: 0.5556\n",
      "Epoch 142/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0330 - accuracy: 0.9557 - val_loss: 1.3933 - val_accuracy: 0.5630\n",
      "Epoch 143/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0481 - accuracy: 0.9576 - val_loss: 1.3657 - val_accuracy: 0.5926\n",
      "Epoch 144/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0310 - accuracy: 0.9557 - val_loss: 1.3287 - val_accuracy: 0.6000\n",
      "Epoch 145/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0320 - accuracy: 0.9631 - val_loss: 1.3639 - val_accuracy: 0.5556\n",
      "Epoch 146/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0368 - accuracy: 0.9520 - val_loss: 1.3950 - val_accuracy: 0.5630\n",
      "Epoch 147/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0357 - accuracy: 0.9705 - val_loss: 1.3778 - val_accuracy: 0.5704\n",
      "Epoch 148/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0326 - accuracy: 0.9613 - val_loss: 1.4219 - val_accuracy: 0.5778\n",
      "Epoch 149/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0379 - accuracy: 0.9410 - val_loss: 1.4652 - val_accuracy: 0.5852\n",
      "Epoch 150/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9557 - val_loss: 1.4435 - val_accuracy: 0.5407\n",
      "Epoch 151/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0316 - accuracy: 0.9520 - val_loss: 1.4348 - val_accuracy: 0.5630\n",
      "Epoch 152/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0313 - accuracy: 0.9502 - val_loss: 1.4629 - val_accuracy: 0.5481\n",
      "Epoch 153/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0346 - accuracy: 0.9539 - val_loss: 1.4847 - val_accuracy: 0.5852\n",
      "Epoch 154/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0324 - accuracy: 0.9539 - val_loss: 1.4997 - val_accuracy: 0.5556\n",
      "Epoch 155/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0314 - accuracy: 0.9686 - val_loss: 1.5152 - val_accuracy: 0.5630\n",
      "Epoch 156/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0331 - accuracy: 0.9613 - val_loss: 1.4710 - val_accuracy: 0.6000\n",
      "Epoch 157/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0303 - accuracy: 0.9613 - val_loss: 1.5245 - val_accuracy: 0.5852\n",
      "Epoch 158/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0324 - accuracy: 0.9576 - val_loss: 1.5650 - val_accuracy: 0.5852\n",
      "Epoch 159/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9576 - val_loss: 1.5153 - val_accuracy: 0.6074\n",
      "Epoch 160/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0321 - accuracy: 0.9668 - val_loss: 1.5083 - val_accuracy: 0.5704\n",
      "Epoch 161/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 0.9723 - val_loss: 1.5517 - val_accuracy: 0.5556\n",
      "Epoch 162/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0376 - accuracy: 0.9539 - val_loss: 1.4472 - val_accuracy: 0.5852\n",
      "Epoch 163/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0350 - accuracy: 0.9576 - val_loss: 1.5671 - val_accuracy: 0.5852\n",
      "Epoch 164/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0344 - accuracy: 0.9613 - val_loss: 1.4585 - val_accuracy: 0.5852\n",
      "Epoch 165/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 0.9742 - val_loss: 1.4828 - val_accuracy: 0.6074\n",
      "Epoch 166/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9502 - val_loss: 1.4969 - val_accuracy: 0.6000\n",
      "Epoch 167/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0322 - accuracy: 0.9631 - val_loss: 1.5200 - val_accuracy: 0.6000\n",
      "Epoch 168/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0337 - accuracy: 0.9613 - val_loss: 1.4948 - val_accuracy: 0.5704\n",
      "Epoch 169/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0298 - accuracy: 0.9668 - val_loss: 1.5452 - val_accuracy: 0.5778\n",
      "Epoch 170/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0311 - accuracy: 0.9594 - val_loss: 1.5446 - val_accuracy: 0.5778\n",
      "Epoch 171/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0298 - accuracy: 0.9594 - val_loss: 1.5790 - val_accuracy: 0.5704\n",
      "Epoch 172/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0305 - accuracy: 0.9576 - val_loss: 1.6134 - val_accuracy: 0.5704\n",
      "Epoch 173/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0293 - accuracy: 0.9557 - val_loss: 1.6224 - val_accuracy: 0.5926\n",
      "Epoch 174/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0291 - accuracy: 0.9557 - val_loss: 1.6109 - val_accuracy: 0.5852\n",
      "Epoch 175/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0318 - accuracy: 0.9557 - val_loss: 1.6392 - val_accuracy: 0.6074\n",
      "Epoch 176/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0307 - accuracy: 0.9649 - val_loss: 1.6283 - val_accuracy: 0.5704\n",
      "Epoch 177/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0317 - accuracy: 0.9576 - val_loss: 1.6237 - val_accuracy: 0.5704\n",
      "Epoch 178/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0329 - accuracy: 0.9520 - val_loss: 1.6302 - val_accuracy: 0.5852\n",
      "Epoch 179/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0354 - accuracy: 0.9557 - val_loss: 1.6929 - val_accuracy: 0.5778\n",
      "Epoch 180/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 0.9834 - val_loss: 1.6612 - val_accuracy: 0.5704\n",
      "Epoch 181/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0357 - accuracy: 0.9594 - val_loss: 1.6772 - val_accuracy: 0.5778\n",
      "Epoch 182/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0311 - accuracy: 0.9649 - val_loss: 1.6945 - val_accuracy: 0.5630\n",
      "Epoch 183/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0351 - accuracy: 0.9483 - val_loss: 1.7191 - val_accuracy: 0.5630\n",
      "Epoch 184/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0322 - accuracy: 0.9446 - val_loss: 1.7002 - val_accuracy: 0.5704\n",
      "Epoch 185/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9594 - val_loss: 1.7060 - val_accuracy: 0.5630\n",
      "Epoch 186/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0327 - accuracy: 0.9576 - val_loss: 1.6268 - val_accuracy: 0.5630\n",
      "Epoch 187/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9613 - val_loss: 1.6773 - val_accuracy: 0.5704\n",
      "Epoch 188/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0289 - accuracy: 0.9631 - val_loss: 1.6597 - val_accuracy: 0.5407\n",
      "Epoch 189/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0295 - accuracy: 0.9649 - val_loss: 1.7628 - val_accuracy: 0.5778\n",
      "Epoch 190/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0339 - accuracy: 0.9613 - val_loss: 1.7175 - val_accuracy: 0.5407\n",
      "Epoch 191/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9631 - val_loss: 1.7793 - val_accuracy: 0.5630\n",
      "Epoch 192/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0314 - accuracy: 0.9631 - val_loss: 1.7509 - val_accuracy: 0.5333\n",
      "Epoch 193/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9705 - val_loss: 1.6526 - val_accuracy: 0.5630\n",
      "Epoch 194/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0382 - accuracy: 0.9410 - val_loss: 1.7004 - val_accuracy: 0.5704\n",
      "Epoch 195/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0276 - accuracy: 0.9668 - val_loss: 1.7281 - val_accuracy: 0.5778\n",
      "Epoch 196/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0373 - accuracy: 0.9613 - val_loss: 1.7708 - val_accuracy: 0.5704\n",
      "Epoch 197/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0390 - accuracy: 0.9354 - val_loss: 1.7570 - val_accuracy: 0.5630\n",
      "Epoch 198/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0317 - accuracy: 0.9594 - val_loss: 1.7869 - val_accuracy: 0.5852\n",
      "Epoch 199/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0311 - accuracy: 0.9631 - val_loss: 1.8085 - val_accuracy: 0.5926\n",
      "Epoch 200/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0353 - accuracy: 0.9576 - val_loss: 1.8129 - val_accuracy: 0.5630\n",
      "Epoch 201/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0316 - accuracy: 0.9668 - val_loss: 1.8293 - val_accuracy: 0.5556\n",
      "Epoch 202/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0289 - accuracy: 0.9686 - val_loss: 1.7781 - val_accuracy: 0.5556\n",
      "Epoch 203/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0322 - accuracy: 0.9539 - val_loss: 1.7952 - val_accuracy: 0.5852\n",
      "Epoch 204/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9686 - val_loss: 1.8373 - val_accuracy: 0.5778\n",
      "Epoch 205/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0303 - accuracy: 0.9649 - val_loss: 1.8592 - val_accuracy: 0.5704\n",
      "Epoch 206/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 0.9686 - val_loss: 1.9117 - val_accuracy: 0.5926\n",
      "Epoch 207/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0339 - accuracy: 0.9594 - val_loss: 1.8742 - val_accuracy: 0.5333\n",
      "Epoch 208/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 0.9502 - val_loss: 1.8246 - val_accuracy: 0.5852\n",
      "Epoch 209/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0318 - accuracy: 0.9705 - val_loss: 1.8745 - val_accuracy: 0.5630\n",
      "Epoch 210/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9539 - val_loss: 1.9352 - val_accuracy: 0.5704\n",
      "Epoch 211/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0349 - accuracy: 0.9631 - val_loss: 1.8371 - val_accuracy: 0.5704\n",
      "Epoch 212/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0330 - accuracy: 0.9686 - val_loss: 1.8505 - val_accuracy: 0.5556\n",
      "Epoch 213/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0343 - accuracy: 0.9557 - val_loss: 1.8486 - val_accuracy: 0.5778\n",
      "Epoch 214/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9779 - val_loss: 1.8961 - val_accuracy: 0.5852\n",
      "Epoch 215/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9668 - val_loss: 1.9109 - val_accuracy: 0.5778\n",
      "Epoch 216/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9742 - val_loss: 1.9798 - val_accuracy: 0.5630\n",
      "Epoch 217/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0342 - accuracy: 0.9557 - val_loss: 1.9341 - val_accuracy: 0.5556\n",
      "Epoch 218/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0308 - accuracy: 0.9576 - val_loss: 2.0069 - val_accuracy: 0.5852\n",
      "Epoch 219/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0372 - accuracy: 0.9465 - val_loss: 1.8412 - val_accuracy: 0.5481\n",
      "Epoch 220/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0316 - accuracy: 0.9668 - val_loss: 1.9095 - val_accuracy: 0.5778\n",
      "Epoch 221/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0315 - accuracy: 0.9594 - val_loss: 1.8989 - val_accuracy: 0.5704\n",
      "Epoch 222/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0290 - accuracy: 0.9668 - val_loss: 1.9879 - val_accuracy: 0.5704\n",
      "Epoch 223/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9539 - val_loss: 1.8906 - val_accuracy: 0.5778\n",
      "Epoch 224/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0286 - accuracy: 0.9631 - val_loss: 1.9385 - val_accuracy: 0.5704\n",
      "Epoch 225/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0393 - accuracy: 0.9410 - val_loss: 1.9317 - val_accuracy: 0.5926\n",
      "Epoch 226/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0346 - accuracy: 0.9649 - val_loss: 1.8873 - val_accuracy: 0.5852\n",
      "Epoch 227/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0300 - accuracy: 0.9723 - val_loss: 1.9174 - val_accuracy: 0.5852\n",
      "Epoch 228/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 0.9649 - val_loss: 1.8441 - val_accuracy: 0.5630\n",
      "Epoch 229/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0320 - accuracy: 0.9594 - val_loss: 1.8452 - val_accuracy: 0.5704\n",
      "Epoch 230/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0335 - accuracy: 0.9594 - val_loss: 1.8868 - val_accuracy: 0.5778\n",
      "Epoch 231/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 0.9649 - val_loss: 1.8849 - val_accuracy: 0.5778\n",
      "Epoch 232/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 0.9705 - val_loss: 1.9641 - val_accuracy: 0.5704\n",
      "Epoch 233/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0291 - accuracy: 0.9668 - val_loss: 2.0103 - val_accuracy: 0.5778\n",
      "Epoch 234/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0302 - accuracy: 0.9576 - val_loss: 2.0431 - val_accuracy: 0.5778\n",
      "Epoch 235/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0337 - accuracy: 0.9557 - val_loss: 1.9826 - val_accuracy: 0.5630\n",
      "Epoch 236/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0318 - accuracy: 0.9594 - val_loss: 1.9634 - val_accuracy: 0.5778\n",
      "Epoch 237/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0291 - accuracy: 0.9705 - val_loss: 1.9208 - val_accuracy: 0.5778\n",
      "Epoch 238/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0362 - accuracy: 0.9576 - val_loss: 1.9555 - val_accuracy: 0.5852\n",
      "Epoch 239/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0329 - accuracy: 0.9520 - val_loss: 2.0093 - val_accuracy: 0.5630\n",
      "Epoch 240/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0291 - accuracy: 0.9576 - val_loss: 2.0767 - val_accuracy: 0.5704\n",
      "Epoch 241/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0326 - accuracy: 0.9576 - val_loss: 2.0714 - val_accuracy: 0.5704\n",
      "Epoch 242/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0267 - accuracy: 0.9815 - val_loss: 2.0748 - val_accuracy: 0.5630\n",
      "Epoch 243/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0311 - accuracy: 0.9594 - val_loss: 2.0834 - val_accuracy: 0.5556\n",
      "Epoch 244/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0291 - accuracy: 0.9613 - val_loss: 2.0845 - val_accuracy: 0.5630\n",
      "Epoch 245/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0319 - accuracy: 0.9631 - val_loss: 2.1351 - val_accuracy: 0.5630\n",
      "Epoch 246/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0376 - accuracy: 0.9391 - val_loss: 2.1438 - val_accuracy: 0.5704\n",
      "Epoch 247/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0273 - accuracy: 0.9742 - val_loss: 2.1463 - val_accuracy: 0.5704\n",
      "Epoch 248/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0296 - accuracy: 0.9613 - val_loss: 2.1179 - val_accuracy: 0.5852\n",
      "Epoch 249/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9594 - val_loss: 2.1675 - val_accuracy: 0.5778\n",
      "Epoch 250/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.9742 - val_loss: 2.1498 - val_accuracy: 0.5556\n",
      "Epoch 251/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9668 - val_loss: 2.1805 - val_accuracy: 0.5704\n",
      "Epoch 252/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0253 - accuracy: 0.9779 - val_loss: 2.2761 - val_accuracy: 0.5704\n",
      "Epoch 253/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 0.9631 - val_loss: 2.2705 - val_accuracy: 0.5630\n",
      "Epoch 254/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0334 - accuracy: 0.9631 - val_loss: 2.2768 - val_accuracy: 0.5704\n",
      "Epoch 255/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0307 - accuracy: 0.9557 - val_loss: 2.2481 - val_accuracy: 0.5778\n",
      "Epoch 256/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 0.9723 - val_loss: 2.2661 - val_accuracy: 0.5704\n",
      "Epoch 257/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0299 - accuracy: 0.9483 - val_loss: 2.2355 - val_accuracy: 0.5630\n",
      "Epoch 258/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9668 - val_loss: 2.2460 - val_accuracy: 0.5556\n",
      "Epoch 259/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0317 - accuracy: 0.9576 - val_loss: 2.2818 - val_accuracy: 0.5704\n",
      "Epoch 260/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 0.9686 - val_loss: 2.2825 - val_accuracy: 0.5630\n",
      "Epoch 261/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0305 - accuracy: 0.9576 - val_loss: 2.2738 - val_accuracy: 0.5704\n",
      "Epoch 262/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0219 - accuracy: 0.9723 - val_loss: 2.3014 - val_accuracy: 0.5556\n",
      "Epoch 263/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9723 - val_loss: 2.3371 - val_accuracy: 0.5704\n",
      "Epoch 264/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0306 - accuracy: 0.9686 - val_loss: 2.3208 - val_accuracy: 0.5704\n",
      "Epoch 265/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0334 - accuracy: 0.9539 - val_loss: 2.3117 - val_accuracy: 0.5407\n",
      "Epoch 266/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0291 - accuracy: 0.9613 - val_loss: 2.3488 - val_accuracy: 0.5630\n",
      "Epoch 267/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0318 - accuracy: 0.9576 - val_loss: 2.4451 - val_accuracy: 0.5481\n",
      "Epoch 268/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0339 - accuracy: 0.9502 - val_loss: 2.4447 - val_accuracy: 0.5556\n",
      "Epoch 269/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0282 - accuracy: 0.9686 - val_loss: 2.4503 - val_accuracy: 0.5407\n",
      "Epoch 270/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0298 - accuracy: 0.9686 - val_loss: 2.4837 - val_accuracy: 0.5630\n",
      "Epoch 271/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9557 - val_loss: 2.5092 - val_accuracy: 0.5630\n",
      "Epoch 272/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0295 - accuracy: 0.9539 - val_loss: 2.4591 - val_accuracy: 0.5704\n",
      "Epoch 273/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0283 - accuracy: 0.9594 - val_loss: 2.4720 - val_accuracy: 0.5778\n",
      "Epoch 274/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0268 - accuracy: 0.9686 - val_loss: 2.5483 - val_accuracy: 0.5704\n",
      "Epoch 275/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0272 - accuracy: 0.9723 - val_loss: 2.5612 - val_accuracy: 0.5852\n",
      "Epoch 276/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0293 - accuracy: 0.9686 - val_loss: 2.5159 - val_accuracy: 0.5852\n",
      "Epoch 277/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0296 - accuracy: 0.9705 - val_loss: 2.5045 - val_accuracy: 0.5778\n",
      "Epoch 278/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9815 - val_loss: 2.5337 - val_accuracy: 0.5778\n",
      "Epoch 279/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0263 - accuracy: 0.9705 - val_loss: 2.5950 - val_accuracy: 0.5926\n",
      "Epoch 280/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 0.9779 - val_loss: 2.6103 - val_accuracy: 0.5852\n",
      "Epoch 281/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0321 - accuracy: 0.9465 - val_loss: 2.6749 - val_accuracy: 0.5704\n",
      "Epoch 282/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0311 - accuracy: 0.9613 - val_loss: 2.5691 - val_accuracy: 0.5852\n",
      "Epoch 283/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0273 - accuracy: 0.9613 - val_loss: 2.5157 - val_accuracy: 0.5778\n",
      "Epoch 284/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9760 - val_loss: 2.6509 - val_accuracy: 0.5630\n",
      "Epoch 285/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0294 - accuracy: 0.9760 - val_loss: 2.4596 - val_accuracy: 0.5926\n",
      "Epoch 286/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0264 - accuracy: 0.9723 - val_loss: 2.5179 - val_accuracy: 0.5852\n",
      "Epoch 287/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0378 - accuracy: 0.9557 - val_loss: 2.6351 - val_accuracy: 0.5704\n",
      "Epoch 288/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0302 - accuracy: 0.9613 - val_loss: 2.2944 - val_accuracy: 0.5926\n",
      "Epoch 289/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 0.9613 - val_loss: 2.5350 - val_accuracy: 0.5704\n",
      "Epoch 290/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 0.9742 - val_loss: 2.5003 - val_accuracy: 0.5778\n",
      "Epoch 291/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0302 - accuracy: 0.9557 - val_loss: 2.5214 - val_accuracy: 0.5778\n",
      "Epoch 292/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0294 - accuracy: 0.9668 - val_loss: 2.5037 - val_accuracy: 0.5704\n",
      "Epoch 293/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0306 - accuracy: 0.9686 - val_loss: 2.5323 - val_accuracy: 0.5852\n",
      "Epoch 294/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0283 - accuracy: 0.9539 - val_loss: 2.4670 - val_accuracy: 0.5778\n",
      "Epoch 295/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9705 - val_loss: 2.4548 - val_accuracy: 0.5704\n",
      "Epoch 296/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0268 - accuracy: 0.9668 - val_loss: 2.4723 - val_accuracy: 0.5704\n",
      "Epoch 297/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 0.9668 - val_loss: 2.5354 - val_accuracy: 0.5778\n",
      "Epoch 298/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9742 - val_loss: 2.5585 - val_accuracy: 0.5630\n",
      "Epoch 299/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 0.9686 - val_loss: 2.6015 - val_accuracy: 0.5630\n",
      "Epoch 300/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 0.9742 - val_loss: 2.6304 - val_accuracy: 0.5778\n",
      "Epoch 301/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0189 - accuracy: 0.9815 - val_loss: 2.6836 - val_accuracy: 0.5630\n",
      "Epoch 302/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9705 - val_loss: 2.6973 - val_accuracy: 0.5704\n",
      "Epoch 303/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9649 - val_loss: 2.6883 - val_accuracy: 0.5704\n",
      "Epoch 304/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0318 - accuracy: 0.9668 - val_loss: 2.6680 - val_accuracy: 0.5704\n",
      "Epoch 305/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0231 - accuracy: 0.9723 - val_loss: 2.5573 - val_accuracy: 0.5778\n",
      "Epoch 306/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 0.9613 - val_loss: 2.5439 - val_accuracy: 0.6148\n",
      "Epoch 307/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0316 - accuracy: 0.9557 - val_loss: 2.5280 - val_accuracy: 0.5926\n",
      "Epoch 308/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9723 - val_loss: 2.4977 - val_accuracy: 0.5778\n",
      "Epoch 309/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0201 - accuracy: 0.9760 - val_loss: 2.5736 - val_accuracy: 0.5704\n",
      "Epoch 310/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9723 - val_loss: 2.6020 - val_accuracy: 0.5778\n",
      "Epoch 311/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0304 - accuracy: 0.9631 - val_loss: 2.6106 - val_accuracy: 0.5630\n",
      "Epoch 312/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9742 - val_loss: 2.6994 - val_accuracy: 0.5556\n",
      "Epoch 313/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0264 - accuracy: 0.9705 - val_loss: 2.7607 - val_accuracy: 0.5630\n",
      "Epoch 314/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9686 - val_loss: 2.7598 - val_accuracy: 0.5778\n",
      "Epoch 315/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0311 - accuracy: 0.9668 - val_loss: 2.7615 - val_accuracy: 0.5704\n",
      "Epoch 316/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.9631 - val_loss: 2.7560 - val_accuracy: 0.5778\n",
      "Epoch 317/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0219 - accuracy: 0.9779 - val_loss: 2.8450 - val_accuracy: 0.5778\n",
      "Epoch 318/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0276 - accuracy: 0.9705 - val_loss: 2.8859 - val_accuracy: 0.5778\n",
      "Epoch 319/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0264 - accuracy: 0.9815 - val_loss: 2.6666 - val_accuracy: 0.5852\n",
      "Epoch 320/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 0.9815 - val_loss: 2.7123 - val_accuracy: 0.5704\n",
      "Epoch 321/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0305 - accuracy: 0.9631 - val_loss: 2.8626 - val_accuracy: 0.5556\n",
      "Epoch 322/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9686 - val_loss: 2.7977 - val_accuracy: 0.5556\n",
      "Epoch 323/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9742 - val_loss: 2.7509 - val_accuracy: 0.5630\n",
      "Epoch 324/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0223 - accuracy: 0.9723 - val_loss: 2.8459 - val_accuracy: 0.5704\n",
      "Epoch 325/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0288 - accuracy: 0.9613 - val_loss: 2.6606 - val_accuracy: 0.5852\n",
      "Epoch 326/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0299 - accuracy: 0.9668 - val_loss: 2.6929 - val_accuracy: 0.5852\n",
      "Epoch 327/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 0.9723 - val_loss: 2.7157 - val_accuracy: 0.5704\n",
      "Epoch 328/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0215 - accuracy: 0.9742 - val_loss: 2.6369 - val_accuracy: 0.5704\n",
      "Epoch 329/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0262 - accuracy: 0.9686 - val_loss: 2.6391 - val_accuracy: 0.5778\n",
      "Epoch 330/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 0.9705 - val_loss: 2.6811 - val_accuracy: 0.5778\n",
      "Epoch 331/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0188 - accuracy: 0.9834 - val_loss: 2.7062 - val_accuracy: 0.5926\n",
      "Epoch 332/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0231 - accuracy: 0.9760 - val_loss: 2.7288 - val_accuracy: 0.5926\n",
      "Epoch 333/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0235 - accuracy: 0.9797 - val_loss: 2.7201 - val_accuracy: 0.5926\n",
      "Epoch 334/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 0.9557 - val_loss: 2.7214 - val_accuracy: 0.6000\n",
      "Epoch 335/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0275 - accuracy: 0.9613 - val_loss: 2.7284 - val_accuracy: 0.5926\n",
      "Epoch 336/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0291 - accuracy: 0.9723 - val_loss: 2.7847 - val_accuracy: 0.6000\n",
      "Epoch 337/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9723 - val_loss: 2.8087 - val_accuracy: 0.5852\n",
      "Epoch 338/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9779 - val_loss: 2.9087 - val_accuracy: 0.5852\n",
      "Epoch 339/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9502 - val_loss: 2.9538 - val_accuracy: 0.5852\n",
      "Epoch 340/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9686 - val_loss: 2.9771 - val_accuracy: 0.5852\n",
      "Epoch 341/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0270 - accuracy: 0.9631 - val_loss: 2.9308 - val_accuracy: 0.5852\n",
      "Epoch 342/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9797 - val_loss: 2.9651 - val_accuracy: 0.5852\n",
      "Epoch 343/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0206 - accuracy: 0.9760 - val_loss: 2.8993 - val_accuracy: 0.6000\n",
      "Epoch 344/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0195 - accuracy: 0.9815 - val_loss: 2.9777 - val_accuracy: 0.5926\n",
      "Epoch 345/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0198 - accuracy: 0.9779 - val_loss: 3.0253 - val_accuracy: 0.5852\n",
      "Epoch 346/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9742 - val_loss: 3.0424 - val_accuracy: 0.5852\n",
      "Epoch 347/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9742 - val_loss: 3.0332 - val_accuracy: 0.5704\n",
      "Epoch 348/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 0.9705 - val_loss: 3.0779 - val_accuracy: 0.5852\n",
      "Epoch 349/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9779 - val_loss: 3.1312 - val_accuracy: 0.5704\n",
      "Epoch 350/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0230 - accuracy: 0.9649 - val_loss: 3.1444 - val_accuracy: 0.5852\n",
      "Epoch 351/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9742 - val_loss: 3.2209 - val_accuracy: 0.5852\n",
      "Epoch 352/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 0.9779 - val_loss: 3.1588 - val_accuracy: 0.5852\n",
      "Epoch 353/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0186 - accuracy: 0.9742 - val_loss: 3.1968 - val_accuracy: 0.5926\n",
      "Epoch 354/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0217 - accuracy: 0.9723 - val_loss: 3.1167 - val_accuracy: 0.5852\n",
      "Epoch 355/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9705 - val_loss: 3.1242 - val_accuracy: 0.5926\n",
      "Epoch 356/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 0.9613 - val_loss: 3.1503 - val_accuracy: 0.6000\n",
      "Epoch 357/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 0.9631 - val_loss: 3.2249 - val_accuracy: 0.6000\n",
      "Epoch 358/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0288 - accuracy: 0.9576 - val_loss: 3.2777 - val_accuracy: 0.6000\n",
      "Epoch 359/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9705 - val_loss: 3.4796 - val_accuracy: 0.5852\n",
      "Epoch 360/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0446 - accuracy: 0.9576 - val_loss: 2.8528 - val_accuracy: 0.5778\n",
      "Epoch 361/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0254 - accuracy: 0.9668 - val_loss: 2.8326 - val_accuracy: 0.5926\n",
      "Epoch 362/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9686 - val_loss: 2.9073 - val_accuracy: 0.5852\n",
      "Epoch 363/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0201 - accuracy: 0.9815 - val_loss: 3.0069 - val_accuracy: 0.5852\n",
      "Epoch 364/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9686 - val_loss: 3.0489 - val_accuracy: 0.5852\n",
      "Epoch 365/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 0.9742 - val_loss: 3.1043 - val_accuracy: 0.5926\n",
      "Epoch 366/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0273 - accuracy: 0.9723 - val_loss: 3.2524 - val_accuracy: 0.5630\n",
      "Epoch 367/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0468 - accuracy: 0.9649 - val_loss: 2.8177 - val_accuracy: 0.5852\n",
      "Epoch 368/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0319 - accuracy: 0.9649 - val_loss: 2.8166 - val_accuracy: 0.5778\n",
      "Epoch 369/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 0.9797 - val_loss: 2.6521 - val_accuracy: 0.5852\n",
      "Epoch 370/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 0.9705 - val_loss: 2.5268 - val_accuracy: 0.5852\n",
      "Epoch 371/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0262 - accuracy: 0.9668 - val_loss: 2.5796 - val_accuracy: 0.5778\n",
      "Epoch 372/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 0.9668 - val_loss: 2.7714 - val_accuracy: 0.5778\n",
      "Epoch 373/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0312 - accuracy: 0.9576 - val_loss: 2.9450 - val_accuracy: 0.5852\n",
      "Epoch 374/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0278 - accuracy: 0.9613 - val_loss: 2.7948 - val_accuracy: 0.5556\n",
      "Epoch 375/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0300 - accuracy: 0.9668 - val_loss: 2.8255 - val_accuracy: 0.5852\n",
      "Epoch 376/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0245 - accuracy: 0.9649 - val_loss: 2.7907 - val_accuracy: 0.5704\n",
      "Epoch 377/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0217 - accuracy: 0.9760 - val_loss: 2.8328 - val_accuracy: 0.5704\n",
      "Epoch 378/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0287 - accuracy: 0.9631 - val_loss: 2.8246 - val_accuracy: 0.5778\n",
      "Epoch 379/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0219 - accuracy: 0.9705 - val_loss: 2.9154 - val_accuracy: 0.5778\n",
      "Epoch 380/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0306 - accuracy: 0.9594 - val_loss: 2.8461 - val_accuracy: 0.5852\n",
      "Epoch 381/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0206 - accuracy: 0.9815 - val_loss: 2.8666 - val_accuracy: 0.5926\n",
      "Epoch 382/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9631 - val_loss: 2.9278 - val_accuracy: 0.5926\n",
      "Epoch 383/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0223 - accuracy: 0.9779 - val_loss: 2.9506 - val_accuracy: 0.5926\n",
      "Epoch 384/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9760 - val_loss: 3.0670 - val_accuracy: 0.5926\n",
      "Epoch 385/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9760 - val_loss: 3.1527 - val_accuracy: 0.5778\n",
      "Epoch 386/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0268 - accuracy: 0.9705 - val_loss: 3.1490 - val_accuracy: 0.5852\n",
      "Epoch 387/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9779 - val_loss: 3.1305 - val_accuracy: 0.5852\n",
      "Epoch 388/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0264 - accuracy: 0.9649 - val_loss: 3.1100 - val_accuracy: 0.5852\n",
      "Epoch 389/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9594 - val_loss: 3.1139 - val_accuracy: 0.5852\n",
      "Epoch 390/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0198 - accuracy: 0.9705 - val_loss: 3.1397 - val_accuracy: 0.5852\n",
      "Epoch 391/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 0.9686 - val_loss: 3.0931 - val_accuracy: 0.5852\n",
      "Epoch 392/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0231 - accuracy: 0.9760 - val_loss: 3.1035 - val_accuracy: 0.5852\n",
      "Epoch 393/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0301 - accuracy: 0.9594 - val_loss: 3.1009 - val_accuracy: 0.6000\n",
      "Epoch 394/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0287 - accuracy: 0.9705 - val_loss: 3.1158 - val_accuracy: 0.5852\n",
      "Epoch 395/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0196 - accuracy: 0.9631 - val_loss: 3.1620 - val_accuracy: 0.5852\n",
      "Epoch 396/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9594 - val_loss: 3.0957 - val_accuracy: 0.5926\n",
      "Epoch 397/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 0.9723 - val_loss: 3.0618 - val_accuracy: 0.5926\n",
      "Epoch 398/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 0.9742 - val_loss: 3.0698 - val_accuracy: 0.5852\n",
      "Epoch 399/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 0.9649 - val_loss: 3.0474 - val_accuracy: 0.5926\n",
      "Epoch 400/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9705 - val_loss: 3.1112 - val_accuracy: 0.5852\n",
      "Epoch 401/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0202 - accuracy: 0.9742 - val_loss: 3.0964 - val_accuracy: 0.5778\n",
      "Epoch 402/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 0.9576 - val_loss: 3.2076 - val_accuracy: 0.5926\n",
      "Epoch 403/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 0.9557 - val_loss: 3.0351 - val_accuracy: 0.6000\n",
      "Epoch 404/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.9594 - val_loss: 3.1466 - val_accuracy: 0.5778\n",
      "Epoch 405/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 0.9760 - val_loss: 3.1670 - val_accuracy: 0.5852\n",
      "Epoch 406/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9705 - val_loss: 3.2115 - val_accuracy: 0.5852\n",
      "Epoch 407/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0179 - accuracy: 0.9779 - val_loss: 3.1449 - val_accuracy: 0.5852\n",
      "Epoch 408/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0304 - accuracy: 0.9576 - val_loss: 3.1518 - val_accuracy: 0.5852\n",
      "Epoch 409/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0198 - accuracy: 0.9742 - val_loss: 3.2439 - val_accuracy: 0.5778\n",
      "Epoch 410/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0217 - accuracy: 0.9779 - val_loss: 3.2963 - val_accuracy: 0.5926\n",
      "Epoch 411/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0233 - accuracy: 0.9649 - val_loss: 3.2759 - val_accuracy: 0.5778\n",
      "Epoch 412/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 0.9668 - val_loss: 3.3722 - val_accuracy: 0.5926\n",
      "Epoch 413/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0295 - accuracy: 0.9557 - val_loss: 3.4258 - val_accuracy: 0.6074\n",
      "Epoch 414/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9686 - val_loss: 3.5156 - val_accuracy: 0.6074\n",
      "Epoch 415/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 0.9871 - val_loss: 3.6010 - val_accuracy: 0.5778\n",
      "Epoch 416/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0299 - accuracy: 0.9668 - val_loss: 3.3447 - val_accuracy: 0.5926\n",
      "Epoch 417/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0231 - accuracy: 0.9797 - val_loss: 3.3682 - val_accuracy: 0.5704\n",
      "Epoch 418/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 0.9649 - val_loss: 3.3370 - val_accuracy: 0.5852\n",
      "Epoch 419/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9723 - val_loss: 3.3972 - val_accuracy: 0.5704\n",
      "Epoch 420/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0278 - accuracy: 0.9705 - val_loss: 3.3009 - val_accuracy: 0.5704\n",
      "Epoch 421/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9539 - val_loss: 3.2898 - val_accuracy: 0.5778\n",
      "Epoch 422/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0186 - accuracy: 0.9797 - val_loss: 3.3805 - val_accuracy: 0.5926\n",
      "Epoch 423/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0220 - accuracy: 0.9668 - val_loss: 3.3827 - val_accuracy: 0.5704\n",
      "Epoch 424/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9686 - val_loss: 3.3049 - val_accuracy: 0.5704\n",
      "Epoch 425/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9668 - val_loss: 3.2688 - val_accuracy: 0.5704\n",
      "Epoch 426/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9668 - val_loss: 3.2809 - val_accuracy: 0.5704\n",
      "Epoch 427/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0172 - accuracy: 0.9815 - val_loss: 3.4275 - val_accuracy: 0.5852\n",
      "Epoch 428/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 0.9686 - val_loss: 3.5567 - val_accuracy: 0.5852\n",
      "Epoch 429/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 0.9594 - val_loss: 3.5551 - val_accuracy: 0.5778\n",
      "Epoch 430/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 0.9686 - val_loss: 3.4852 - val_accuracy: 0.5926\n",
      "Epoch 431/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0196 - accuracy: 0.9779 - val_loss: 3.4576 - val_accuracy: 0.5778\n",
      "Epoch 432/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9705 - val_loss: 3.4865 - val_accuracy: 0.5852\n",
      "Epoch 433/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9520 - val_loss: 3.4827 - val_accuracy: 0.6000\n",
      "Epoch 434/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9705 - val_loss: 3.4917 - val_accuracy: 0.5704\n",
      "Epoch 435/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0283 - accuracy: 0.9631 - val_loss: 3.4590 - val_accuracy: 0.5852\n",
      "Epoch 436/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0267 - accuracy: 0.9649 - val_loss: 3.6229 - val_accuracy: 0.5778\n",
      "Epoch 437/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0187 - accuracy: 0.9834 - val_loss: 3.6738 - val_accuracy: 0.5852\n",
      "Epoch 438/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0284 - accuracy: 0.9613 - val_loss: 3.6424 - val_accuracy: 0.5778\n",
      "Epoch 439/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9705 - val_loss: 3.6916 - val_accuracy: 0.5778\n",
      "Epoch 440/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0187 - accuracy: 0.9779 - val_loss: 3.6631 - val_accuracy: 0.5852\n",
      "Epoch 441/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 0.9815 - val_loss: 3.6764 - val_accuracy: 0.5852\n",
      "Epoch 442/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0162 - accuracy: 0.9852 - val_loss: 3.6826 - val_accuracy: 0.5778\n",
      "Epoch 443/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0194 - accuracy: 0.9742 - val_loss: 3.7037 - val_accuracy: 0.5852\n",
      "Epoch 444/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0340 - accuracy: 0.9520 - val_loss: 3.7151 - val_accuracy: 0.5630\n",
      "Epoch 445/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 0.9613 - val_loss: 3.6245 - val_accuracy: 0.5704\n",
      "Epoch 446/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9594 - val_loss: 3.6673 - val_accuracy: 0.5556\n",
      "Epoch 447/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0201 - accuracy: 0.9705 - val_loss: 3.7237 - val_accuracy: 0.5778\n",
      "Epoch 448/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0158 - accuracy: 0.9834 - val_loss: 3.7399 - val_accuracy: 0.5704\n",
      "Epoch 449/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9705 - val_loss: 3.8386 - val_accuracy: 0.5704\n",
      "Epoch 450/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0232 - accuracy: 0.9723 - val_loss: 3.7954 - val_accuracy: 0.5704\n",
      "Epoch 451/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0341 - accuracy: 0.9483 - val_loss: 3.7323 - val_accuracy: 0.5778\n",
      "Epoch 452/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9742 - val_loss: 3.7622 - val_accuracy: 0.5778\n",
      "Epoch 453/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 0.9649 - val_loss: 3.8483 - val_accuracy: 0.5556\n",
      "Epoch 454/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 0.9613 - val_loss: 3.6790 - val_accuracy: 0.5778\n",
      "Epoch 455/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9779 - val_loss: 3.7054 - val_accuracy: 0.5704\n",
      "Epoch 456/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0310 - accuracy: 0.9576 - val_loss: 3.7764 - val_accuracy: 0.5852\n",
      "Epoch 457/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 0.9742 - val_loss: 3.9090 - val_accuracy: 0.5852\n",
      "Epoch 458/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 0.9797 - val_loss: 3.7288 - val_accuracy: 0.5704\n",
      "Epoch 459/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0193 - accuracy: 0.9742 - val_loss: 3.6091 - val_accuracy: 0.5778\n",
      "Epoch 460/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0197 - accuracy: 0.9815 - val_loss: 3.7534 - val_accuracy: 0.5926\n",
      "Epoch 461/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0219 - accuracy: 0.9668 - val_loss: 3.8484 - val_accuracy: 0.5852\n",
      "Epoch 462/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0167 - accuracy: 0.9797 - val_loss: 3.8477 - val_accuracy: 0.5852\n",
      "Epoch 463/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0198 - accuracy: 0.9760 - val_loss: 3.9052 - val_accuracy: 0.5926\n",
      "Epoch 464/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0189 - accuracy: 0.9779 - val_loss: 3.9628 - val_accuracy: 0.5778\n",
      "Epoch 465/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9594 - val_loss: 3.9843 - val_accuracy: 0.5704\n",
      "Epoch 466/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0231 - accuracy: 0.9742 - val_loss: 3.8099 - val_accuracy: 0.5926\n",
      "Epoch 467/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0184 - accuracy: 0.9815 - val_loss: 4.0011 - val_accuracy: 0.5852\n",
      "Epoch 468/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0200 - accuracy: 0.9760 - val_loss: 4.0873 - val_accuracy: 0.5926\n",
      "Epoch 469/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9668 - val_loss: 4.0926 - val_accuracy: 0.5926\n",
      "Epoch 470/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0276 - accuracy: 0.9613 - val_loss: 3.9265 - val_accuracy: 0.5852\n",
      "Epoch 471/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0179 - accuracy: 0.9742 - val_loss: 4.1065 - val_accuracy: 0.5778\n",
      "Epoch 472/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0327 - accuracy: 0.9465 - val_loss: 3.9310 - val_accuracy: 0.5778\n",
      "Epoch 473/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0152 - accuracy: 0.9779 - val_loss: 3.9350 - val_accuracy: 0.5852\n",
      "Epoch 474/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0207 - accuracy: 0.9797 - val_loss: 4.0193 - val_accuracy: 0.5778\n",
      "Epoch 475/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0147 - accuracy: 0.9889 - val_loss: 3.9247 - val_accuracy: 0.5778\n",
      "Epoch 476/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0229 - accuracy: 0.9723 - val_loss: 3.8398 - val_accuracy: 0.5704\n",
      "Epoch 477/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9760 - val_loss: 3.9281 - val_accuracy: 0.5926\n",
      "Epoch 478/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 0.9631 - val_loss: 3.9244 - val_accuracy: 0.5778\n",
      "Epoch 479/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0178 - accuracy: 0.9815 - val_loss: 3.9940 - val_accuracy: 0.5926\n",
      "Epoch 480/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0208 - accuracy: 0.9705 - val_loss: 4.0582 - val_accuracy: 0.5926\n",
      "Epoch 481/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0177 - accuracy: 0.9779 - val_loss: 4.0457 - val_accuracy: 0.5926\n",
      "Epoch 482/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9742 - val_loss: 3.9420 - val_accuracy: 0.5926\n",
      "Epoch 483/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9649 - val_loss: 3.8729 - val_accuracy: 0.5778\n",
      "Epoch 484/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 0.9557 - val_loss: 3.9068 - val_accuracy: 0.5852\n",
      "Epoch 485/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0273 - accuracy: 0.9705 - val_loss: 3.8253 - val_accuracy: 0.5852\n",
      "Epoch 486/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 0.9649 - val_loss: 3.9548 - val_accuracy: 0.5778\n",
      "Epoch 487/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0192 - accuracy: 0.9779 - val_loss: 4.0673 - val_accuracy: 0.5852\n",
      "Epoch 488/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0200 - accuracy: 0.9742 - val_loss: 4.0054 - val_accuracy: 0.5852\n",
      "Epoch 489/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0208 - accuracy: 0.9779 - val_loss: 3.5058 - val_accuracy: 0.5778\n",
      "Epoch 490/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9649 - val_loss: 3.7720 - val_accuracy: 0.5704\n",
      "Epoch 491/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0213 - accuracy: 0.9705 - val_loss: 3.4704 - val_accuracy: 0.5778\n",
      "Epoch 492/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 0.9723 - val_loss: 3.5531 - val_accuracy: 0.5556\n",
      "Epoch 493/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0180 - accuracy: 0.9815 - val_loss: 3.5552 - val_accuracy: 0.5630\n",
      "Epoch 494/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9815 - val_loss: 3.7777 - val_accuracy: 0.5778\n",
      "Epoch 495/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0163 - accuracy: 0.9760 - val_loss: 3.7522 - val_accuracy: 0.5704\n",
      "Epoch 496/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0229 - accuracy: 0.9723 - val_loss: 3.8374 - val_accuracy: 0.5704\n",
      "Epoch 497/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0205 - accuracy: 0.9760 - val_loss: 3.8205 - val_accuracy: 0.5481\n",
      "Epoch 498/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0195 - accuracy: 0.9723 - val_loss: 3.7968 - val_accuracy: 0.5704\n",
      "Epoch 499/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9705 - val_loss: 3.6748 - val_accuracy: 0.5630\n",
      "Epoch 500/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 0.9649 - val_loss: 3.6479 - val_accuracy: 0.5704\n",
      "Epoch 501/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 0.9723 - val_loss: 3.9101 - val_accuracy: 0.5704\n",
      "Epoch 502/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9668 - val_loss: 3.9614 - val_accuracy: 0.5852\n",
      "Epoch 503/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0197 - accuracy: 0.9779 - val_loss: 3.8753 - val_accuracy: 0.6000\n",
      "Epoch 504/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0172 - accuracy: 0.9779 - val_loss: 3.8901 - val_accuracy: 0.5852\n",
      "Epoch 505/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0177 - accuracy: 0.9797 - val_loss: 4.0062 - val_accuracy: 0.5704\n",
      "Epoch 506/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0173 - accuracy: 0.9834 - val_loss: 3.9701 - val_accuracy: 0.5926\n",
      "Epoch 507/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 0.9668 - val_loss: 3.9594 - val_accuracy: 0.5852\n",
      "Epoch 508/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9649 - val_loss: 3.9556 - val_accuracy: 0.5852\n",
      "Epoch 509/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9723 - val_loss: 4.0415 - val_accuracy: 0.5778\n",
      "Epoch 510/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0170 - accuracy: 0.9815 - val_loss: 3.9772 - val_accuracy: 0.5778\n",
      "Epoch 511/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 0.9760 - val_loss: 3.9552 - val_accuracy: 0.5778\n",
      "Epoch 512/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0148 - accuracy: 0.9760 - val_loss: 3.9536 - val_accuracy: 0.5630\n",
      "Epoch 513/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9760 - val_loss: 3.8706 - val_accuracy: 0.5556\n",
      "Epoch 514/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0189 - accuracy: 0.9742 - val_loss: 3.9591 - val_accuracy: 0.5778\n",
      "Epoch 515/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0207 - accuracy: 0.9686 - val_loss: 3.9965 - val_accuracy: 0.5704\n",
      "Epoch 516/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0173 - accuracy: 0.9779 - val_loss: 4.1381 - val_accuracy: 0.5704\n",
      "Epoch 517/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0199 - accuracy: 0.9742 - val_loss: 4.1735 - val_accuracy: 0.5778\n",
      "Epoch 518/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9705 - val_loss: 4.0852 - val_accuracy: 0.5852\n",
      "Epoch 519/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 0.9760 - val_loss: 4.1136 - val_accuracy: 0.5926\n",
      "Epoch 520/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0166 - accuracy: 0.9797 - val_loss: 4.1191 - val_accuracy: 0.5852\n",
      "Epoch 521/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0202 - accuracy: 0.9705 - val_loss: 4.1171 - val_accuracy: 0.5926\n",
      "Epoch 522/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9686 - val_loss: 4.1067 - val_accuracy: 0.5852\n",
      "Epoch 523/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 0.9686 - val_loss: 4.1590 - val_accuracy: 0.5852\n",
      "Epoch 524/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0178 - accuracy: 0.9705 - val_loss: 4.1914 - val_accuracy: 0.5704\n",
      "Epoch 525/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 0.9815 - val_loss: 4.2251 - val_accuracy: 0.5704\n",
      "Epoch 526/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0191 - accuracy: 0.9723 - val_loss: 4.3300 - val_accuracy: 0.5852\n",
      "Epoch 527/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9760 - val_loss: 4.3537 - val_accuracy: 0.5704\n",
      "Epoch 528/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 0.9779 - val_loss: 4.3235 - val_accuracy: 0.5852\n",
      "Epoch 529/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0222 - accuracy: 0.9631 - val_loss: 4.2782 - val_accuracy: 0.5852\n",
      "Epoch 530/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9815 - val_loss: 4.2702 - val_accuracy: 0.5852\n",
      "Epoch 531/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0175 - accuracy: 0.9760 - val_loss: 4.4166 - val_accuracy: 0.5926\n",
      "Epoch 532/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0198 - accuracy: 0.9815 - val_loss: 4.2857 - val_accuracy: 0.5778\n",
      "Epoch 533/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 0.9686 - val_loss: 4.1904 - val_accuracy: 0.5630\n",
      "Epoch 534/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 0.9760 - val_loss: 4.2778 - val_accuracy: 0.5630\n",
      "Epoch 535/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9742 - val_loss: 4.2827 - val_accuracy: 0.5778\n",
      "Epoch 536/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 0.9631 - val_loss: 4.1355 - val_accuracy: 0.5852\n",
      "Epoch 537/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0287 - accuracy: 0.9594 - val_loss: 4.1201 - val_accuracy: 0.5704\n",
      "Epoch 538/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0253 - accuracy: 0.9649 - val_loss: 3.8976 - val_accuracy: 0.5481\n",
      "Epoch 539/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0234 - accuracy: 0.9742 - val_loss: 4.1794 - val_accuracy: 0.5407\n",
      "Epoch 540/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9723 - val_loss: 4.1051 - val_accuracy: 0.5407\n",
      "Epoch 541/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0214 - accuracy: 0.9686 - val_loss: 3.9962 - val_accuracy: 0.5852\n",
      "Epoch 542/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9686 - val_loss: 3.8268 - val_accuracy: 0.5630\n",
      "Epoch 543/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9723 - val_loss: 3.6965 - val_accuracy: 0.5778\n",
      "Epoch 544/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 0.9760 - val_loss: 4.2277 - val_accuracy: 0.5852\n",
      "Epoch 545/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0181 - accuracy: 0.9852 - val_loss: 4.4250 - val_accuracy: 0.5704\n",
      "Epoch 546/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0148 - accuracy: 0.9815 - val_loss: 4.4381 - val_accuracy: 0.5852\n",
      "Epoch 547/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9668 - val_loss: 4.4431 - val_accuracy: 0.5630\n",
      "Epoch 548/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0199 - accuracy: 0.9742 - val_loss: 4.4059 - val_accuracy: 0.5556\n",
      "Epoch 549/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0169 - accuracy: 0.9834 - val_loss: 4.2657 - val_accuracy: 0.5778\n",
      "Epoch 550/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0215 - accuracy: 0.9686 - val_loss: 4.2537 - val_accuracy: 0.5778\n",
      "Epoch 551/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0204 - accuracy: 0.9686 - val_loss: 4.3325 - val_accuracy: 0.5704\n",
      "Epoch 552/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 0.9723 - val_loss: 4.4208 - val_accuracy: 0.5926\n",
      "Epoch 553/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0181 - accuracy: 0.9742 - val_loss: 4.3600 - val_accuracy: 0.5926\n",
      "Epoch 554/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0195 - accuracy: 0.9760 - val_loss: 4.3489 - val_accuracy: 0.5852\n",
      "Epoch 555/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0189 - accuracy: 0.9668 - val_loss: 4.3037 - val_accuracy: 0.5704\n",
      "Epoch 556/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0214 - accuracy: 0.9686 - val_loss: 4.2942 - val_accuracy: 0.5630\n",
      "Epoch 557/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0174 - accuracy: 0.9834 - val_loss: 4.2454 - val_accuracy: 0.5852\n",
      "Epoch 558/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0159 - accuracy: 0.9815 - val_loss: 4.3708 - val_accuracy: 0.5852\n",
      "Epoch 559/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9705 - val_loss: 4.4828 - val_accuracy: 0.5852\n",
      "Epoch 560/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0202 - accuracy: 0.9742 - val_loss: 3.8642 - val_accuracy: 0.5778\n",
      "Epoch 561/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0341 - accuracy: 0.9391 - val_loss: 4.3441 - val_accuracy: 0.5259\n",
      "Epoch 562/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0219 - accuracy: 0.9815 - val_loss: 4.0604 - val_accuracy: 0.5481\n",
      "Epoch 563/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9649 - val_loss: 4.2002 - val_accuracy: 0.5333\n",
      "Epoch 564/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9705 - val_loss: 4.1188 - val_accuracy: 0.5333\n",
      "Epoch 565/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 0.9668 - val_loss: 4.1007 - val_accuracy: 0.5407\n",
      "Epoch 566/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 0.9668 - val_loss: 4.0232 - val_accuracy: 0.5407\n",
      "Epoch 567/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9815 - val_loss: 4.0665 - val_accuracy: 0.5481\n",
      "Epoch 568/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0189 - accuracy: 0.9797 - val_loss: 4.0736 - val_accuracy: 0.5481\n",
      "Epoch 569/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0262 - accuracy: 0.9631 - val_loss: 4.0210 - val_accuracy: 0.5630\n",
      "Epoch 570/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 0.9705 - val_loss: 4.0654 - val_accuracy: 0.5704\n",
      "Epoch 571/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0270 - accuracy: 0.9649 - val_loss: 4.0953 - val_accuracy: 0.5556\n",
      "Epoch 572/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 0.9686 - val_loss: 4.1282 - val_accuracy: 0.5630\n",
      "Epoch 573/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0171 - accuracy: 0.9760 - val_loss: 4.1454 - val_accuracy: 0.5630\n",
      "Epoch 574/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9686 - val_loss: 4.1738 - val_accuracy: 0.5481\n",
      "Epoch 575/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0177 - accuracy: 0.9723 - val_loss: 4.2209 - val_accuracy: 0.5481\n",
      "Epoch 576/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9723 - val_loss: 4.1893 - val_accuracy: 0.5778\n",
      "Epoch 577/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0193 - accuracy: 0.9779 - val_loss: 4.1932 - val_accuracy: 0.5630\n",
      "Epoch 578/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0181 - accuracy: 0.9760 - val_loss: 4.1869 - val_accuracy: 0.5630\n",
      "Epoch 579/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0154 - accuracy: 0.9834 - val_loss: 4.2736 - val_accuracy: 0.5704\n",
      "Epoch 580/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0186 - accuracy: 0.9742 - val_loss: 4.2227 - val_accuracy: 0.5556\n",
      "Epoch 581/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0198 - accuracy: 0.9760 - val_loss: 4.2438 - val_accuracy: 0.5630\n",
      "Epoch 582/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 0.9705 - val_loss: 4.1134 - val_accuracy: 0.5852\n",
      "Epoch 583/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0200 - accuracy: 0.9779 - val_loss: 4.1548 - val_accuracy: 0.5704\n",
      "Epoch 584/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0200 - accuracy: 0.9723 - val_loss: 4.2480 - val_accuracy: 0.5778\n",
      "Epoch 585/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 0.9686 - val_loss: 4.3377 - val_accuracy: 0.5630\n",
      "Epoch 586/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9631 - val_loss: 4.2701 - val_accuracy: 0.5778\n",
      "Epoch 587/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 0.9723 - val_loss: 4.2164 - val_accuracy: 0.5704\n",
      "Epoch 588/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0198 - accuracy: 0.9797 - val_loss: 4.2294 - val_accuracy: 0.5704\n",
      "Epoch 589/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0161 - accuracy: 0.9797 - val_loss: 4.2430 - val_accuracy: 0.5778\n",
      "Epoch 590/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0169 - accuracy: 0.9834 - val_loss: 4.2848 - val_accuracy: 0.5704\n",
      "Epoch 591/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0208 - accuracy: 0.9686 - val_loss: 4.3002 - val_accuracy: 0.5778\n",
      "Epoch 592/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9742 - val_loss: 4.2644 - val_accuracy: 0.5704\n",
      "Epoch 593/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0137 - accuracy: 0.9852 - val_loss: 4.1800 - val_accuracy: 0.5704\n",
      "Epoch 594/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0148 - accuracy: 0.9889 - val_loss: 4.2432 - val_accuracy: 0.5704\n",
      "Epoch 595/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0232 - accuracy: 0.9742 - val_loss: 4.3021 - val_accuracy: 0.5630\n",
      "Epoch 596/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0190 - accuracy: 0.9779 - val_loss: 4.3011 - val_accuracy: 0.5704\n",
      "Epoch 597/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0178 - accuracy: 0.9760 - val_loss: 4.2904 - val_accuracy: 0.5630\n",
      "Epoch 598/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9686 - val_loss: 4.3895 - val_accuracy: 0.5778\n",
      "Epoch 599/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0152 - accuracy: 0.9779 - val_loss: 4.3333 - val_accuracy: 0.5630\n",
      "Epoch 600/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0156 - accuracy: 0.9797 - val_loss: 4.3918 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f7d656e50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(train_ds, epochs=600, validation_data=val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e983bd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0273667e-22 0.0000000e+00 9.9379224e-01 0.0000000e+00 1.2602389e-13\n",
      "  2.0065544e-22 1.9785194e-25 0.0000000e+00]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "OU\n"
     ]
    }
   ],
   "source": [
    "# Dragapult\n",
    "sample = {\n",
    "    \"hp\": 88,\n",
    "    \"atk\": 120,\n",
    "    \"def\": 75,\n",
    "    \"spa\": 100,\n",
    "    \"spd\": 75,\n",
    "    \"speed\": 142,\n",
    "    \"ability1\": \"Clear Body\",\n",
    "    \"ability2\": \"Infiltrator\",\n",
    "    \"ability3\": \"Cursed Body\",\n",
    "    \"type1\": \"Dragon\",\n",
    "    \"type2\": \"Ghost\",\n",
    "    #\"strongestAttack\": 130,\n",
    "    #\"recovery\": 0,\n",
    "    #\"coverageAttacks\": 12,\n",
    "    #\"prevo\": 0\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = model.predict(input_dict)\n",
    "\n",
    "print(predictions)\n",
    "print(mlb.classes_)\n",
    "print(mlb.classes_[np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b8e540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growlithe-Hisui\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "LC\n",
      "\n",
      "Arcanine-Hisui\n",
      "[[1.8011942e-33 0.0000000e+00 0.0000000e+00 1.9007439e-07 4.7470908e-25\n",
      "  9.9454767e-01 1.4276599e-31 3.4663767e-24]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "UU\n",
      "\n",
      "Voltorb-Hisui\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "LC\n",
      "\n",
      "Electrode-Hisui\n",
      "[[1.2866423e-32 2.1174442e-07 1.0964530e-20 1.6024434e-25 3.3684086e-05\n",
      "  8.7163190e-27 3.1904010e-34 0.0000000e+00]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "RU\n",
      "\n",
      "Typhlosion-Hisui\n",
      "[[2.0986835e-22 5.6528471e-10 1.0396371e-15 3.6180808e-08 9.4743091e-01\n",
      "  1.6038501e-10 3.3923117e-23 4.0341357e-27]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "RU\n",
      "\n",
      "Qwilfish-Hisui\n",
      "[[9.0337621e-24 0.0000000e+00 0.0000000e+00 6.3427029e-23 0.0000000e+00\n",
      "  1.4435647e-29 0.0000000e+00 9.9998939e-01]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "ZU\n",
      "\n",
      "Sneasel-Hisui\n",
      "[[3.1416965e-17 2.3073815e-02 3.8263771e-16 2.0722118e-03 7.0267998e-02\n",
      "  4.3020664e-14 3.9506658e-19 7.2357309e-21]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "RU\n",
      "\n",
      "Samurott-Hisui\n",
      "[[3.4919151e-22 0.0000000e+00 1.5719690e-20 6.2763817e-08 9.6869330e-09\n",
      "  7.9372674e-01 2.3004557e-22 9.6102433e-21]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "UU\n",
      "\n",
      "Lilligant-Hisui\n",
      "[[3.9997138e-30 0.0000000e+00 0.0000000e+00 3.2509215e-02 1.4474157e-26\n",
      "  5.6011158e-05 0.0000000e+00 4.4006576e-08]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "PU\n",
      "\n",
      "Zorua-Hisui\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "LC\n",
      "\n",
      "Zoroark-Hisui\n",
      "[[1.2998052e-23 2.7545154e-01 3.8971478e-22 4.2715116e-14 1.0398004e-06\n",
      "  5.0269144e-24 5.1809218e-27 2.3567138e-32]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "NU\n",
      "\n",
      "Braviary-Hisui\n",
      "[[4.4915875e-20 1.4627115e-05 1.0528912e-16 1.7401948e-05 8.5077244e-01\n",
      "  1.9230008e-11 2.6048307e-21 1.5834566e-22]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "RU\n",
      "\n",
      "Sliggoo-Hisui\n",
      "[[1.3791659e-13 3.4571551e-07 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 2.5111627e-30]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "NU\n",
      "\n",
      "Goodra-Hisui\n",
      "[[4.6308842e-25 2.2507871e-10 2.4497702e-11 6.6006723e-25 2.7855311e-04\n",
      "  1.3295817e-19 5.1829597e-26 0.0000000e+00]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "RU\n",
      "\n",
      "Avalugg-Hisui\n",
      "[[3.3717553e-33 0.0000000e+00 0.0000000e+00 9.6619539e-23 0.0000000e+00\n",
      "  2.3944971e-29 0.0000000e+00 1.0000000e+00]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "ZU\n",
      "\n",
      "Decidueye-Hisui\n",
      "[[1.3451212e-26 9.7421908e-01 6.3633597e-28 5.8935450e-07 2.2331435e-04\n",
      "  3.7168067e-25 5.0252312e-30 6.4763397e-32]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "NU\n",
      "\n",
      "Wyrdeer\n",
      "[[1.11865026e-35 0.00000000e+00 0.00000000e+00 7.49260420e-04\n",
      "  2.51594325e-33 3.24517069e-03 0.00000000e+00 1.38315510e-08]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "UU\n",
      "\n",
      "Kleavor\n",
      "[[8.1159146e-14 2.4732668e-05 3.5276980e-25 9.4959134e-01 3.0402571e-08\n",
      "  3.9948938e-12 6.9994697e-24 3.9130373e-06]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "PU\n",
      "\n",
      "Ursaluna\n",
      "[[7.0009629e-17 6.7020051e-26 8.8576180e-01 8.2767116e-29 4.1455125e-05\n",
      "  6.1552868e-13 1.3093636e-18 0.0000000e+00]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "OU\n",
      "\n",
      "Basculegion\n",
      "[[7.4243968e-24 1.0404091e-33 0.0000000e+00 7.2995174e-01 4.6149961e-17\n",
      "  3.2605323e-07 3.1892643e-37 6.0979422e-05]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "PU\n",
      "\n",
      "Sneasler\n",
      "[[1.50183419e-18 8.71670199e-38 9.67500329e-01 7.74475346e-31\n",
      "  1.30629205e-08 7.43361015e-12 5.68323456e-18 0.00000000e+00]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "OU\n",
      "\n",
      "Overqwil\n",
      "[[5.5820365e-25 0.0000000e+00 0.0000000e+00 5.9364915e-01 6.3618156e-25\n",
      "  1.8906643e-08 0.0000000e+00 6.3437740e-03]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "PU\n",
      "\n",
      "Enamorus\n",
      "[[1.0839672e-22 0.0000000e+00 9.7868377e-01 0.0000000e+00 1.2407260e-18\n",
      "  1.0731425e-22 2.8949577e-20 0.0000000e+00]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "OU\n",
      "\n",
      "Enamorus-Therian\n",
      "[[6.3910809e-24 4.2575587e-38 1.7390290e-20 2.0307742e-09 2.9210803e-05\n",
      "  6.6147469e-02 1.6243900e-26 3.6148005e-25]]\n",
      "['LC' 'NU' 'OU' 'PU' 'RU' 'UU' 'Uber' 'ZU']\n",
      "UU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"./hisui.csv\", keep_default_na=False)\n",
    "\n",
    "for index, entry in dataframe.iterrows():\n",
    "    print(entry[\"name\"])\n",
    "    input_dict = {name: tf.convert_to_tensor([value]) for name, value in entry.items() if name != 'tier' and name != 'name'}\n",
    "    \n",
    "    predictions = model.predict(input_dict)\n",
    "\n",
    "    print(predictions)\n",
    "    print(mlb.classes_)\n",
    "    print(mlb.classes_[np.argmax(predictions)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab3dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9153ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
